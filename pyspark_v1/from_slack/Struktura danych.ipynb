{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5795bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    IntegerType, LongType, FloatType, DoubleType,\n",
    "    StringType, DateType, TimestampType, BooleanType,\n",
    "    MapType, ArrayType\n",
    ")\n",
    "\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ce844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+---+----------+--------+\n",
      "| id|      name|cost_net|vat|cost_gross|category|\n",
      "+---+----------+--------+---+----------+--------+\n",
      "|  1|Bindownica| 2003.46|  8|   2163.74|       B|\n",
      "|  2| Telewizor| 1144.24|  5|   1201.45|       H|\n",
      "+---+----------+--------+---+----------+--------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- cost_net: string (nullable = true)\n",
      " |-- vat: string (nullable = true)\n",
      " |-- cost_gross: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with SparkSession.builder.appName(\"pyspark-struktura-danych\").getOrCreate() as spark:\n",
    "    # Definiowanie schematu\n",
    "    product_schema = StructType(\n",
    "        [\n",
    "            StructField(\"ID\", IntegerType(), False),\n",
    "            StructField(\"name\", StringType(), False),\n",
    "            StructField(\"cost_net\", DoubleType(), False),\n",
    "            StructField(\"vat\", IntegerType(), False),\n",
    "            StructField(\"cost_gross\", DoubleType(), False),\n",
    "            StructField(\"category\", StringType(), False)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df = spark.read.format(\"csv\") \\\n",
    "        .options(header=True, delimeter=\",\", schema=product_schema) \\\n",
    "        .load(\"./work/data/products.csv\")\n",
    "\n",
    "    df.show(2)\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37c85b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- cost_net: double (nullable = true)\n",
      " |-- vat: integer (nullable = true)\n",
      " |-- cost_gross: double (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with SparkSession.builder.appName(\"pyspark-struktura-danych\").getOrCreate() as spark:\n",
    "    # Definiowanie schematu\n",
    "    product_schema = StructType(\n",
    "        [\n",
    "            StructField(\"ID\", IntegerType(), False),\n",
    "            StructField(\"name\", StringType(), False),\n",
    "            StructField(\"cost_net\", DoubleType(), False),\n",
    "            StructField(\"vat\", IntegerType(), False),\n",
    "            StructField(\"cost_gross\", DoubleType(), False),\n",
    "            StructField(\"category\", StringType(), False)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df = spark.read.format(\"csv\") \\\n",
    "        .options(header=True, delimeter=\",\", schema=product_schema) \\\n",
    "        .load(\"./work/data/products.csv\")\n",
    "        \n",
    "    df_final = spark.createDataFrame([], schema=product_schema)\n",
    "\n",
    "    # Rzutowanie/Castowaniem typ√≥w danych\n",
    "    df_pre_csv = df.select(\n",
    "        f.col(\"id\").cast(IntegerType()).alias(\"ID\"),\n",
    "        f.col(\"name\").cast(StringType()),\n",
    "        f.col(\"cost_net\").cast(DoubleType()),\n",
    "        f.col(\"vat\").cast(IntegerType()),\n",
    "        f.col(\"cost_gross\").cast(DoubleType()),\n",
    "        f.col(\"category\").cast(StringType())\n",
    "    )\n",
    "    \n",
    "    df_final = df_final.union(df_pre_csv)\n",
    "    df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066a1caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+----+--------+--------------------------------+---------+------+\n",
      "|balans_konta|data_utworzenia_konta|imie|nazwisko|timestamp_ostatniej_aktualizacji|typ_konta|waluta|\n",
      "+------------+---------------------+----+--------+--------------------------------+---------+------+\n",
      "|     1500.75|           2021-03-15| Jan|Kowalski|            2023-10-05T14:30:00Z|      VIP|  NULL|\n",
      "|      2300.5|           2020-07-22|Anna|   Nowak|            2023-09-28T09:45:00Z|     NULL|   PLN|\n",
      "+------------+---------------------+----+--------+--------------------------------+---------+------+\n",
      "\n",
      "root\n",
      " |-- balans_konta: double (nullable = true)\n",
      " |-- data_utworzenia_konta: string (nullable = true)\n",
      " |-- imie: string (nullable = true)\n",
      " |-- nazwisko: string (nullable = true)\n",
      " |-- timestamp_ostatniej_aktualizacji: string (nullable = true)\n",
      " |-- typ_konta: string (nullable = true)\n",
      " |-- waluta: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with SparkSession.builder.appName(\"pyspark-files\").getOrCreate() as spark:\n",
    "    df = spark.read.format(\"json\").options(multiLine=True, inferSchema=False).load(\"./work/data/users.json\")\n",
    "    df.show()\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba526f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-------------------+\n",
      "|fname|   lname|balance|         updated_at|\n",
      "+-----+--------+-------+-------------------+\n",
      "|  Jan|Kowalski|1500.75|2023-10-05 14:30:00|\n",
      "| Anna|   Nowak| 2300.5|2023-09-28 09:45:00|\n",
      "+-----+--------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with SparkSession.builder.appName(\"pyspark-files\").getOrCreate() as spark:\n",
    "    users_schema = StructType(\n",
    "        [\n",
    "            StructField(\"fname\", StringType(), False),\n",
    "            StructField(\"lname\", StringType(), False),\n",
    "            StructField(\"balance\", DoubleType(), False),\n",
    "            StructField(\"updated_at\", TimestampType(), False),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df = spark.read.format(\"json\").options(multiLine=True).load(\"./work/data/users.json\")\n",
    "\n",
    "    df_users = df.select(\n",
    "        f.col(\"imie\").cast(StringType()).alias(\"fname\"),\n",
    "        f.col(\"nazwisko\").cast(StringType()).alias(\"lname\"),\n",
    "        f.col(\"balans_konta\").cast(DoubleType()).alias(\"balance\"),\n",
    "        f.col(\"timestamp_ostatniej_aktualizacji\").cast(TimestampType()).alias(\"updated_at\"),\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f093757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
